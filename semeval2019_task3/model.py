# AUTOGENERATED! DO NOT EDIT! File to edit: 01_task3.ipynb (unless otherwise specified).

__all__ = ['seed_all', 'loss_reweight', 'metrics', 'f1_score', 'F1Micro']

# Cell
def seed_all(seed_value=42):
    """random seeding Python and torch"""
    random.seed(seed_value) # Python
    np.random.seed(seed_value) # cpu vars
    torch.manual_seed(seed_value) # cpu  vars

    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed_value)
        torch.cuda.manual_seed_all(seed_value) # gpu vars
        torch.backends.cudnn.deterministic = True  #needed
        torch.backends.cudnn.benchmark = False

# Cell
def loss_reweight(pred, y_b):
    """cross entropy loss with reweighting"""
    loss_label = loss_criterion(pred, y_b.view(-1).cuda()).cuda()
    loss_label = torch.matmul(torch.gather(weight_label, 0, y_b.view(-1).cuda()), loss_label) / \
                 y_b.view(-1).shape[0]

    return loss_label

# Cell
def metrics(logits, labels):
    cm = torch.zeros((4,4))
    preds = torch.argmax(logits, dim=1)
    acc = (labels == preds).float().mean()
    for label, pred in zip(labels.view(-1), preds.view(-1)):
        cm[label.long(), pred.long()] += 1

    tp = cm.diagonal()[:3].sum()
    fp = cm[:, :3].sum() - tp
    fn = cm[:3, :].sum() - tp
    return {'val_acc': acc, 'tp': tp, 'fp': fp, 'fn': fn}

def f1_score(tp, fp, fn):
    prec_rec_f1 = {}
    prec_rec_f1['precision'] = tp / (tp + fp)
    prec_rec_f1['recall'] = tp / (tp + fn)
    prec_rec_f1['f1_score'] = 2 * (prec_rec_f1['precision'] * prec_rec_f1['recall']) / (prec_rec_f1['precision'] + prec_rec_f1['recall'])
    return prec_rec_f1

# Cell
class F1Micro(Callback):
    """custom loss for fast.ai"""
    def on_epoch_begin(self, **kwargs):
        self.out, self.target = torch.empty(0), torch.empty(0)

    def on_batch_end(self, last_output, last_target, **kwargs):
        self.out = torch.cat((self.out.type(last_output.cpu().type()), last_output.cpu()))
        self.target = torch.cat((self.target.type(last_target.cpu().type()), last_target.cpu()))

    def on_epoch_end(self, last_metrics, **kwargs):
        assert self.out.shape[0] == self.target.shape[0]
        metric = metrics(self.out, self.target)
        f1_dict = f1_score(metric['tp'], metric['fp'], metric['fn'])
        return add_metrics(last_metrics, [f1_dict['f1_score'].numpy()] )