---

title: FastBert for SemEval-2019 Task 3

keywords: fastai
sidebar: home_sidebar

summary: "We are applying Bert to SemEval-2019 Task 3. See this article for the challenge setting: https://www.aclweb.org/anthology/S19-2005.pdf. We use the customization work from the notebook 00_fastbert to connect Bert with fast.ai (seperated sequences approach)."
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 01_task3.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/phil/Projects/venv/consult/lib/python3.7/site-packages/ekphrasis/classes/tokenizer.py:225: FutureWarning: Possible nested set at position 2190
  self.tok = re.compile(r&#34;({})&#34;.format(&#34;|&#34;.join(pipeline)))
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Reading twitter - 1grams ...
Reading twitter - 2grams ...
Reading twitter - 1grams ...
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/phil/Projects/venv/consult/lib/python3.7/site-packages/ekphrasis/classes/exmanager.py:14: FutureWarning: Possible nested set at position 42
  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># for the other models from huggingfaces go to</span>
<span class="c1"># https://www.kaggle.com/maroberti/fastai-with-transformers-bert-roberta</span>
<span class="c1"># notebook will work as well</span>
<span class="c1"># just pay attention at the customized model section</span>

<span class="n">model_class</span><span class="p">,</span> <span class="n">tokenizer_class</span><span class="p">,</span> <span class="n">config_class</span> <span class="o">=</span> <span class="n">BertForSequenceClassification</span><span class="p">,</span> <span class="n">BertTokenizer</span><span class="p">,</span> <span class="n">BertConfig</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># get the data as dataframes </span>
<span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;./data/train.txt&#39;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s1">&#39;id&#39;</span><span class="p">)</span>
<span class="n">dev</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;./data/dev.txt&#39;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s1">&#39;id&#39;</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;./data/test.txt&#39;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s1">&#39;id&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>turn1</th>
      <th>turn2</th>
      <th>turn3</th>
      <th>label</th>
    </tr>
    <tr>
      <th>id</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2442</th>
      <td>I like parle g</td>
      <td>You were promised Parle G?</td>
      <td>For</td>
      <td>others</td>
    </tr>
    <tr>
      <th>15558</th>
      <td>Tell me now or i will cry</td>
      <td>don't cry ðŸ˜¿</td>
      <td>I am crying</td>
      <td>sad</td>
    </tr>
    <tr>
      <th>9388</th>
      <td>Sorry bro my phone better is low</td>
      <td>whats ur phone background?</td>
      <td>Sorry ..</td>
      <td>sad</td>
    </tr>
    <tr>
      <th>20754</th>
      <td>Can I join you tonight</td>
      <td>not going be home</td>
      <td>Get lost</td>
      <td>angry</td>
    </tr>
    <tr>
      <th>17500</th>
      <td>Tell me one thing do u want to be my love in c...</td>
      <td>I WOULD LOVE THAT SO MUCH:)</td>
      <td>It will amazing</td>
      <td>happy</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># preprocessing steps for the turns</span>
<span class="c1"># for details check out the process_pipeline function</span>
<span class="c1"># we are not applying much preprocessing in order</span>
<span class="c1"># to keep the input as raw as possible for Bert</span>
<span class="c1"># just simple steps like smileys, all_caps, repeated words</span>
<span class="c1"># are handled as they differ more from the source used to pre-train Bert</span>
<span class="c1"># check out the original Bert paper for details</span>
<span class="c1"># https://arxiv.org/pdf/1810.04805v2.pdf</span>
<span class="k">for</span> <span class="n">turn</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;turn1&#39;</span><span class="p">,</span> <span class="s1">&#39;turn2&#39;</span><span class="p">,</span> <span class="s1">&#39;turn3&#39;</span><span class="p">]:</span> 
    <span class="n">train</span><span class="p">[</span><span class="n">turn</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">turn</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">process_pipeline</span><span class="p">)</span>
    <span class="n">dev</span><span class="p">[</span><span class="n">turn</span><span class="p">]</span> <span class="o">=</span> <span class="n">dev</span><span class="p">[</span><span class="n">turn</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">process_pipeline</span><span class="p">)</span>
    <span class="n">test</span><span class="p">[</span><span class="n">turn</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="n">turn</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">process_pipeline</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># lookup for labels</span>
<span class="n">EMOS_DIC</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;happy&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s1">&#39;angry&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
            <span class="s1">&#39;sad&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
            <span class="s1">&#39;others&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># make sure FastAi gets the order of labels for the special loss function</span>
<span class="n">train</span><span class="o">.</span><span class="n">label</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">label</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">EMOS_DIC</span><span class="p">[</span><span class="n">x</span><span class="p">])</span>
<span class="n">dev</span><span class="o">.</span><span class="n">label</span> <span class="o">=</span> <span class="n">dev</span><span class="o">.</span><span class="n">label</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">EMOS_DIC</span><span class="p">[</span><span class="n">x</span><span class="p">])</span>
<span class="n">test</span><span class="o">.</span><span class="n">label</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">label</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">EMOS_DIC</span><span class="p">[</span><span class="n">x</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="seed_all" class="doc_header"><code>seed_all</code><a href="https://github.com/PhilippMaxx/semeval2019_task3/tree/master/semeval2019_task3/model.py#L28" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>seed_all</code>(<strong><code>seed_value</code></strong>=<em><code>42</code></em>)</p>
</blockquote>
<p>random seeding Python and torch</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">seed_all</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># setting up the processors for fast.ai TextList </span>
<span class="n">pretrained_model_name</span> <span class="o">=</span> <span class="s1">&#39;bert-large-uncased-whole-word-masking&#39;</span>

<span class="n">transformer_tokenizer</span> <span class="o">=</span> <span class="n">tokenizer_class</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">pretrained_model_name</span><span class="p">)</span>
<span class="n">transformer_base_tokenizer</span> <span class="o">=</span> <span class="n">TransformersBaseTokenizer</span><span class="p">(</span><span class="n">pretrained_tokenizer</span> <span class="o">=</span> <span class="n">transformer_tokenizer</span><span class="p">,</span> <span class="n">model_type</span> <span class="o">=</span> <span class="n">model_type</span><span class="p">)</span>
<span class="n">fastai_tokenizer</span> <span class="o">=</span> <span class="n">SeqTokenizer</span><span class="p">(</span><span class="n">tok_func</span> <span class="o">=</span> <span class="n">transformer_base_tokenizer</span><span class="p">,</span> <span class="n">pre_rules</span><span class="o">=</span><span class="p">[],</span> <span class="n">post_rules</span><span class="o">=</span><span class="p">[])</span>
<span class="n">tokenize_processor</span> <span class="o">=</span> <span class="n">SeqTokenizeProcessor</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">fastai_tokenizer</span><span class="p">,</span> <span class="n">include_bos</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">include_eos</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">transformer_vocab</span> <span class="o">=</span>  <span class="n">TransformersVocab</span><span class="p">(</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">transformer_tokenizer</span><span class="p">)</span>
<span class="n">numericalize_processor</span> <span class="o">=</span> <span class="n">NumericalizeProcessor</span><span class="p">(</span><span class="n">vocab</span><span class="o">=</span><span class="n">transformer_vocab</span><span class="p">)</span>

<span class="n">transformer_processor</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenize_processor</span><span class="p">,</span> <span class="n">numericalize_processor</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># padding token</span>
<span class="n">pad_idx</span> <span class="o">=</span> <span class="n">transformer_tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># setting up the databunch</span>
<span class="n">databunch</span> <span class="o">=</span> <span class="p">(</span><span class="n">TextList</span><span class="o">.</span><span class="n">from_df</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">cols</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;turn1&#39;</span><span class="p">,</span> <span class="s1">&#39;turn2&#39;</span><span class="p">,</span> <span class="s1">&#39;turn3&#39;</span><span class="p">],</span> <span class="n">processor</span><span class="o">=</span><span class="n">transformer_processor</span><span class="p">)</span>
             <span class="o">.</span><span class="n">split_none</span><span class="p">()</span>
             <span class="o">.</span><span class="n">label_from_df</span><span class="p">(</span><span class="n">cols</span><span class="o">=</span> <span class="s1">&#39;label&#39;</span><span class="p">)</span>
             <span class="o">.</span><span class="n">databunch</span><span class="p">(</span><span class="n">bs</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">pad_first</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pad_idx</span><span class="o">=</span><span class="n">pad_idx</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># batchsizes have to be devidors of the length of the data </span>
<span class="c1"># with TextList objects the last batch would be cut if not</span>
<span class="c1"># it would cut the last not size fitting batch out completly</span>
<span class="c1"># to validate on new data we have to create a dataloader</span>
<span class="c1"># most easiest way is to use the datablock api from FastAi</span>

<span class="n">databunch</span><span class="o">.</span><span class="n">valid_dl</span> <span class="o">=</span> <span class="p">(</span><span class="n">TextList</span><span class="o">.</span><span class="n">from_df</span><span class="p">(</span><span class="n">dev</span><span class="p">,</span> <span class="n">cols</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;turn1&#39;</span><span class="p">,</span> <span class="s1">&#39;turn2&#39;</span><span class="p">,</span> <span class="s1">&#39;turn3&#39;</span><span class="p">],</span> <span class="n">processor</span><span class="o">=</span><span class="n">transformer_processor</span><span class="p">)</span>
                      <span class="o">.</span><span class="n">split_none</span><span class="p">()</span>
                      <span class="o">.</span><span class="n">label_from_df</span><span class="p">(</span><span class="n">cols</span><span class="o">=</span> <span class="s1">&#39;label&#39;</span><span class="p">)</span>
                      <span class="o">.</span><span class="n">databunch</span><span class="p">(</span><span class="n">bs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">pad_first</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pad_idx</span><span class="o">=</span><span class="n">pad_idx</span><span class="p">))</span><span class="o">.</span><span class="n">train_dl</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_dl</span> <span class="o">=</span> <span class="p">(</span><span class="n">TextList</span><span class="o">.</span><span class="n">from_df</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">cols</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;turn1&#39;</span><span class="p">,</span> <span class="s1">&#39;turn2&#39;</span><span class="p">,</span> <span class="s1">&#39;turn3&#39;</span><span class="p">],</span> <span class="n">processor</span><span class="o">=</span><span class="n">transformer_processor</span><span class="p">)</span>
             <span class="o">.</span><span class="n">split_none</span><span class="p">()</span>
             <span class="o">.</span><span class="n">label_from_df</span><span class="p">(</span><span class="n">cols</span><span class="o">=</span> <span class="s1">&#39;label&#39;</span><span class="p">)</span>
             <span class="o">.</span><span class="n">databunch</span><span class="p">(</span><span class="n">bs</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">pad_first</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pad_idx</span><span class="o">=</span><span class="n">pad_idx</span><span class="p">))</span><span class="o">.</span><span class="n">train_dl</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Model-setup">Model setup<a class="anchor-link" href="#Model-setup">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">config</span> <span class="o">=</span> <span class="n">config_class</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">pretrained_model_name</span><span class="p">)</span>
<span class="n">config</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">config</span><span class="o">.</span><span class="n">use_bfloat16</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># False</span>
<span class="nb">print</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>{
  &#34;attention_probs_dropout_prob&#34;: 0.1,
  &#34;finetuning_task&#34;: null,
  &#34;hidden_act&#34;: &#34;gelu&#34;,
  &#34;hidden_dropout_prob&#34;: 0.1,
  &#34;hidden_size&#34;: 1024,
  &#34;initializer_range&#34;: 0.02,
  &#34;intermediate_size&#34;: 4096,
  &#34;is_decoder&#34;: false,
  &#34;layer_norm_eps&#34;: 1e-12,
  &#34;max_position_embeddings&#34;: 512,
  &#34;num_attention_heads&#34;: 16,
  &#34;num_hidden_layers&#34;: 24,
  &#34;num_labels&#34;: 4,
  &#34;output_attentions&#34;: false,
  &#34;output_hidden_states&#34;: false,
  &#34;output_past&#34;: true,
  &#34;pruned_heads&#34;: {},
  &#34;torchscript&#34;: false,
  &#34;type_vocab_size&#34;: 2,
  &#34;use_bfloat16&#34;: true,
  &#34;vocab_size&#34;: 30522
}

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># create the customized model from the pretrained Bert weights</span>
<span class="n">transformer_model</span> <span class="o">=</span> <span class="n">model_class</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">pretrained_model_name</span><span class="p">,</span> <span class="n">config</span> <span class="o">=</span> <span class="n">config</span><span class="p">)</span>
<span class="n">custom_transformer_model</span> <span class="o">=</span> <span class="n">CustomTransformerModel</span><span class="p">(</span><span class="n">transformer_model</span> <span class="o">=</span> <span class="n">transformer_model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Loss-and-Metrices">Loss and Metrices<a class="anchor-link" href="#Loss-and-Metrices">&#182;</a></h2><p>As one can see in the article of the challenge we have a special requirement for the metrices. Also as the data is imbalanced it would be a good idea to reweight the loss function.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># the weights result from the balances of the train dataset</span>
<span class="n">weight_list</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.3198680179</span><span class="p">,</span> <span class="mf">0.246494733</span><span class="p">,</span> <span class="mf">0.2484349259</span><span class="p">,</span> <span class="mf">1.74527696</span><span class="p">]</span>
<span class="n">weight_label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">weight_list</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">loss_criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="loss_reweight" class="doc_header"><code>loss_reweight</code><a href="https://github.com/PhilippMaxx/semeval2019_task3/tree/master/semeval2019_task3/model.py#L41" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>loss_reweight</code>(<strong><code>pred</code></strong>, <strong><code>y_b</code></strong>)</p>
</blockquote>
<p>cross entropy loss with reweighting</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Note that we are trying to maximize the micro-averaged F1 score for the three emotion classes - Happy, Sad and Angry. To be precise, the defined metric goes as follows:</p>
\begin{equation*}
P_{\mu } = \frac{\sum T P_{i}}{\sum (T P_{i} + F P_{i})} \forall i \in \{ Happy, Sad, Angry \}
\end{equation*}\begin{equation*}
R_{\mu } = \frac{\sum T P_{i}}{\sum (T P_{i} + F N_{i})} \forall i \in \{ Happy, Sad, Angry \}
\end{equation*}<p>With $T P_{i}$, $F P_{i}$, $F N_{i}$ are the true postives, false positives and false negatives of class $i$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Hence we will write $F 1_{\mu}$ as a customized metric.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="fastai.metrics" class="doc_header"><code>fastai.metrics</code><a href="fastai/metrics.py#L0" class="source_link" style="float:right">[source]</a></h4><p>Implements various metrics to measure training accuracy</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="f1_score" class="doc_header"><code>f1_score</code><a href="https://github.com/PhilippMaxx/semeval2019_task3/tree/master/semeval2019_task3/model.py#L62" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>f1_score</code>(<strong><code>tp</code></strong>, <strong><code>fp</code></strong>, <strong><code>fn</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Credits for the metrics: <a href="https://github.com/juliusberner/emotion_transformer/blob/master/01_model.ipynb">https://github.com/juliusberner/emotion_transformer/blob/master/01_model.ipynb</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="F1Micro" class="doc_header"><code>class</code> <code>F1Micro</code><a href="https://github.com/PhilippMaxx/semeval2019_task3/tree/master/semeval2019_task3/model.py#L70" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>F1Micro</code>() :: <code>Callback</code></p>
</blockquote>
<p>custom loss for fast.ai</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We also thought about mixup in the learner as data augumentation. For now we don't know how to apply it here as we have word level embeddings with three different turns what makes it from a logical standpoint in language not really usefull. We could shift the embeddings by a mean of the turn word embeddings of the shuffled version batch but that might lead also to no better results. So something one could experiment with :)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AdamW</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="n">CustomAdamW</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">AdamW</span><span class="p">,</span> <span class="n">correct_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">learner</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">databunch</span><span class="p">,</span> 
                  <span class="n">custom_transformer_model</span><span class="p">,</span> 
                  <span class="n">opt_func</span> <span class="o">=</span> <span class="n">CustomAdamW</span><span class="p">,</span> 
                  <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">F1Micro</span><span class="p">()],</span>
                  <span class="n">loss_func</span><span class="o">=</span><span class="n">loss_reweight</span><span class="p">,</span>
                  <span class="n">callback_fns</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span><span class="n">GradientClipping</span><span class="p">,</span> <span class="n">clip</span><span class="o">=</span><span class="mf">0.888</span><span class="p">))</span>

<span class="c1"># Show graph of learner stats and metrics after each epoch.</span>
<span class="n">learner</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ShowGraph</span><span class="p">(</span><span class="n">learner</span><span class="p">))</span>
<span class="c1"># learner.callbacks.append(SaveModelCallback(learner, every=&#39;improvement&#39;, monitor=&#39;valid_loss&#39;, name=&#39;best_model&#39;))</span>

<span class="c1"># Put learn in FP16 precision mode</span>
<span class="n">learner</span> <span class="o">=</span> <span class="n">learner</span><span class="o">.</span><span class="n">to_fp16</span><span class="p">()</span> <span class="c1"># delete the line if fp16 is not wanted</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learner</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>CustomTransformerModel
======================================================================
Layer (type)         Output Shape         Param #    Trainable 
======================================================================
Embedding            [64, 1024]           31,254,528 True      
______________________________________________________________________
Embedding            [64, 1024]           524,288    True      
______________________________________________________________________
Embedding            [64, 1024]           2,048      True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Dropout              [16, 64, 64]         0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 4096]           4,198,400  True      
______________________________________________________________________
Linear               [64, 1024]           4,195,328  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Dropout              [16, 64, 64]         0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 4096]           4,198,400  True      
______________________________________________________________________
Linear               [64, 1024]           4,195,328  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Dropout              [16, 64, 64]         0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 4096]           4,198,400  True      
______________________________________________________________________
Linear               [64, 1024]           4,195,328  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Dropout              [16, 64, 64]         0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 4096]           4,198,400  True      
______________________________________________________________________
Linear               [64, 1024]           4,195,328  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Dropout              [16, 64, 64]         0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 4096]           4,198,400  True      
______________________________________________________________________
Linear               [64, 1024]           4,195,328  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Dropout              [16, 64, 64]         0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 4096]           4,198,400  True      
______________________________________________________________________
Linear               [64, 1024]           4,195,328  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Dropout              [16, 64, 64]         0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 4096]           4,198,400  True      
______________________________________________________________________
Linear               [64, 1024]           4,195,328  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Dropout              [16, 64, 64]         0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 4096]           4,198,400  True      
______________________________________________________________________
Linear               [64, 1024]           4,195,328  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Dropout              [16, 64, 64]         0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 4096]           4,198,400  True      
______________________________________________________________________
Linear               [64, 1024]           4,195,328  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Dropout              [16, 64, 64]         0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 4096]           4,198,400  True      
______________________________________________________________________
Linear               [64, 1024]           4,195,328  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Dropout              [16, 64, 64]         0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 4096]           4,198,400  True      
______________________________________________________________________
Linear               [64, 1024]           4,195,328  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Dropout              [16, 64, 64]         0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 4096]           4,198,400  True      
______________________________________________________________________
Linear               [64, 1024]           4,195,328  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Dropout              [16, 64, 64]         0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 4096]           4,198,400  True      
______________________________________________________________________
Linear               [64, 1024]           4,195,328  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Dropout              [16, 64, 64]         0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 4096]           4,198,400  True      
______________________________________________________________________
Linear               [64, 1024]           4,195,328  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Dropout              [16, 64, 64]         0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 4096]           4,198,400  True      
______________________________________________________________________
Linear               [64, 1024]           4,195,328  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Dropout              [16, 64, 64]         0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 4096]           4,198,400  True      
______________________________________________________________________
Linear               [64, 1024]           4,195,328  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Dropout              [16, 64, 64]         0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 4096]           4,198,400  True      
______________________________________________________________________
Linear               [64, 1024]           4,195,328  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Dropout              [16, 64, 64]         0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 4096]           4,198,400  True      
______________________________________________________________________
Linear               [64, 1024]           4,195,328  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Dropout              [16, 64, 64]         0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 4096]           4,198,400  True      
______________________________________________________________________
Linear               [64, 1024]           4,195,328  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Dropout              [16, 64, 64]         0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 4096]           4,198,400  True      
______________________________________________________________________
Linear               [64, 1024]           4,195,328  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Dropout              [16, 64, 64]         0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 4096]           4,198,400  True      
______________________________________________________________________
Linear               [64, 1024]           4,195,328  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Dropout              [16, 64, 64]         0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 4096]           4,198,400  True      
______________________________________________________________________
Linear               [64, 1024]           4,195,328  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Dropout              [16, 64, 64]         0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 4096]           4,198,400  True      
______________________________________________________________________
Linear               [64, 1024]           4,195,328  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
Dropout              [16, 64, 64]         0          False     
______________________________________________________________________
Linear               [64, 1024]           1,049,600  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [64, 4096]           4,198,400  True      
______________________________________________________________________
Linear               [64, 1024]           4,195,328  True      
______________________________________________________________________
LayerNorm            [64, 1024]           2,048      True      
______________________________________________________________________
Dropout              [64, 1024]           0          False     
______________________________________________________________________
Linear               [1024]               1,049,600  True      
______________________________________________________________________
Tanh                 [1024]               0          False     
______________________________________________________________________
Dropout              [1024]               0          False     
______________________________________________________________________
Linear               [4]                  4,100      True      
______________________________________________________________________

Total params: 335,145,988
Total trainable params: 335,145,988
Total non-trainable params: 0
Optimized with &#39;transformers.optimization.AdamW&#39;, correct_bias=False
Using true weight decay as discussed in https://www.fast.ai/2018/07/02/adam-weight-decay/ 
Loss function : function
======================================================================
Callbacks functions applied 
    ShowGraph
    MixedPrecision</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learner</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;untrain&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">seed_all</span><span class="p">()</span> <span class="c1"># make sure we have same seeds when rerunning</span>
<span class="n">learner</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;untrain&#39;</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># With other examples of fast.ai combined with Bert models </span>
<span class="c1"># we saw people trying to use the fast.ai version what is </span>
<span class="c1"># also used in training ulmfit </span>
<span class="c1"># Namely unfreezing the model layer-by-layer </span>
<span class="c1"># One has to keep in mind that this is a good practice </span>
<span class="c1"># for ulmfit but not for Bert models </span>
<span class="c1"># When fine tuning ulmfit there is a first phase of fine-tuning </span>
<span class="c1"># the models langauge model to adapt to the specific language in </span>
<span class="c1"># the training data </span>
<span class="c1"># Then a fine-tuning in classification takes place</span>
<span class="c1"># With bert the fine-tuning of the language and classification </span>
<span class="c1"># takes place simultane</span>
<span class="n">learner</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learner</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
<span class="n">learner</span><span class="o">.</span><span class="n">recorder</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">suggestion</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.
Min numerical gradient: 2.29E-04
Min loss divided by 10: 1.32E-03
</pre>
</div>
</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># -- results of manual hyperparameter search --</span>

<span class="c1"># Note that in this challenge it was allowed to validate</span>
<span class="c1"># on the test data in the last phase of the challenge</span>
<span class="c1"># as the data is really messy one has to be extra cautious</span>

<span class="c1"># ---------------------------------------------</span>

<span class="c1"># f1_micro_test 74.8% - (2, 1e-04, (0.9,0.8)) - overfitting on train dataset</span>
<span class="c1"># f1_micro_test 75.14% - (2, 1e-04, (0.8,0.7))</span>
<span class="c1"># f1_micro_test 75.21% - (3, 1e-04, (0.8,0.7))</span>
<span class="c1"># f1_micro_test 75.3% - (2, 1.25e-04, (0.85,0.75))</span>
<span class="c1"># f1_micro_test 75.5% - (2, 1.1e-04, (0.85,0.75))</span>
<span class="c1"># f1_micro_test 75.6% - (3, 1.1e-04, (0.85,0.75))</span>
<span class="c1"># f1_micro_test 75.67% - (2, 0.94e-05, (0.85,0.75))</span>
<span class="c1"># f1_micro_test 75.9% (val: 76.52%) - (2, 0.8e-04, (0.85,0.75))</span>
<span class="c1"># f1_micro_test 76.01% - (2, 1e-04, (0.85,0.75))</span>
<span class="c1"># f1_micro_test 76.21% - (2, 0.98e-04, (0.85,0.75)), (2, 0.95e-04, (0.85,0.75))</span>

<span class="c1"># ---------------------------------------------</span>


<span class="n">learner</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_lr</span><span class="o">=</span><span class="mf">1e-04</span><span class="p">,</span> <span class="n">moms</span><span class="o">=</span><span class="p">(</span><span class="mf">0.85</span><span class="p">,</span><span class="mf">0.75</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>f1_micro</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.209308</td>
      <td>0.205090</td>
      <td>0.923049</td>
      <td>0.747452</td>
      <td>05:43</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.147107</td>
      <td>0.233982</td>
      <td>0.924501</td>
      <td>0.758545</td>
      <td>05:43</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXxV1b338c/vDJlDyMiQAAmDDDIPAo44VaSKtnUeql4tt63W1tv2KR2eVq3ttU8nO6itWuvtoNait44tVsWiRRCQQeYZEgIkhIxkTtbzxznEgBkOEHKSc77v1yuvZu+9ztm/s3v8srP22mubcw4REen9POEuQEREuoYCXUQkQijQRUQihAJdRCRCKNBFRCKEL1w7zsjIcLm5uRSW1VByuJ4RWcnE+fXvi4hIR1auXHnQOZfZ1rawBXpubi4rVqxg+g/fIKaijmfuOptxOSnhKkdEpFcws93tbQv7KfGBijoAahubwlyJiEjv1mmgm9mTZlZkZus6aTfNzBrN7KoTKaSmXoEuInIyQjlDfwqY3VEDM/MCPwJeP56dt75LtVqBLiJyUjrtQ3fOLTaz3E6afQl4Hph2PDsvq25o+b22QYEuIh1raGigoKCA2tracJdyysXFxZGTk4Pf7w/5NSd9UdTMsoFPAedzHIG+t6yG7/zto16cGgW6iHSioKCA5ORkcnNzMbNwl3PKOOcoKSmhoKCAvLy8kF/XFRdFHwK+4Zxr7qyhmc0zsxVmtuLQ4Xpe/XBfyzZ1uYhIZ2pra0lPT4/oMAcwM9LT04/7L5GuGLY4FXg2eIAzgDlm1uic+9uxDZ1zjwGPAcQOGHHUNI/qchGRUER6mB9xIp/zpAPdOdfy94CZPQW80laYt8cMvGZU1jaebCkiIlEtlGGLzwDvASPNrMDMbjezz5vZ57uigKRYH30T/JTXNHTeWEQkjMrKynjkkUeO+3Vz5syhrKzsFFR0tFBGuVwf6ps552493gKSY33Ex3ipUKCLSA93JNC/+MUvHrW+sbERn6/9OH3ttddOdWlAGG/9PyI5zk9SnI+ymvpwlyIi0qH58+ezfft2Jk6ciN/vJy4ujtTUVDZt2sSWLVu48soryc/Pp7a2li9/+cvMmzcP+Giqk6qqKi699FLOPvtslixZQnZ2Ni+++CLx8fFdUl/YAz0+xkvfeD/7KyJ/XKmIdJ37Xl7PhsKKLn3PMQP78L3LT293+4MPPsi6detYvXo1b7/9Np/85CdZt25dy9DCJ598krS0NGpqapg2bRqf+cxnSE9PP+o9tm7dyjPPPMPjjz/ONddcw/PPP89NN93UJfWHfS4Xr8fITo1n58HDVNXpwqiI9B5nnHHGUePEf/nLXzJhwgRmzJhBfn4+W7du/dhr8vLymDhxIgBTpkxh165dXVZP2M/QDfjEmP784b3dfLC7lHNPa3NWSBGRo3R0Jt1dEhMTW35/++23eeONN3jvvfdISEhg1qxZbY4jj42Nbfnd6/VSU1PTZfWE/QzdDE7rlwTAzoOHw1yNiEj7kpOTqaysbHNbeXk5qampJCQksGnTJpYuXdrN1fWIM3QjMzmWxBivAl1EerT09HTOOussxo4dS3x8PP369WvZNnv2bH7zm98wevRoRo4cyYwZM7q9vrAHOha4IyovM5EdCnQR6eGefvrpNtfHxsby97//vc1tR/rJMzIyWLfuozmsvva1r3VpbWHvcvEE727Ny0hiR3FVeIsREenFwh7oEwelApCTGs/+8lqam10nrxARkbaENdCvmDiQr33iNAD6JcfS2Ow4VK0bjERETkRYA31CTl983kAJ/frEAVAUfMaoiIgcn7AGus/70fSQ/VMCgb7nkC6MioiciLAGuqfVfL+nD0whKdbHu9sOhrEiEZHeK7xn6J6PAj3G52H0gGS27NdIFxGJDElJgZsmCwsLueqqq9psM2vWLFasWNEl+wtroHs9Rz+RY2hGEtuKq3BOI11EJHIMHDiQBQsWnPL99KhAnzEsjWOfNSoi0lPMnz+fhx9+uGX53nvv5YEHHuDCCy9k8uTJjBs3jhdffPFjr9u1axdjx44FoKamhuuuu47Ro0fzqU99qkvncgnrnaLHBvoVE7L5ycItvLS6kMvGDwxTVSLSK/x9Puz/sGvfs/84uPTBdjdfe+21fOUrX+HOO+8E4LnnnmPhwoXcfffd9OnTh4MHDzJjxgzmzp3b7jNBH330URISEti4cSNr165l8uTJXVZ+WAPd5zn6DwSPxxiUFk+pxqKLSA80adIkioqKKCwspLi4mNTUVPr3788999zD4sWL8Xg87N27lwMHDtC/f/8232Px4sXcfffdAIwfP57x48d3WX1hPkP/+LrkOD/5h6q7vxgR6V06OJM+la6++moWLFjA/v37ufbaa/nzn/9McXExK1euxO/3k5ub2+a0ud2hxwxbPCI5zkdlrR50ISI907XXXsuzzz7LggULuPrqqykvLycrKwu/38+iRYvYvXt3h68/99xzWyb4WrduHWvXru2y2npUHzpAnzg/FbV6YLSI9Eynn346lZWVZGdnM2DAAG688UYuv/xyxo0bx9SpUxk1alSHr//CF77AbbfdxujRoxk9ejRTpkzpstrCGuieNgI9Oc5HVV0jzc2uze0iIuH24YcfXYzNyMjgvffea7NdVVXgvprc3NyWaXPj4+N59tlnT0ldnXa5mNmTZlZkZuva2X6jma01sw/NbImZTQh55210uaTE+3EOiqs0p4uIyPEIpQ/9KWB2B9t3Auc558YB3wceC3nnbZyAzxoZeKboy2sKQ30bEREhhEB3zi0GDnWwfYlzrjS4uBTICXXn3jbO0IdnJTNhUF+eWrKL6npdHBWRo0XLneQn8jm7epTL7UDbz2ACzGyema0wsxXB5TbbffPSURSU1vD0sj1dXJ6I9GZxcXGUlJREfKg75ygpKSEuLu64XtdlF0XN7HwCgX52e22cc48R7JKJHTDCtXfNc8bQdLL7xrM6v6yryhORCJCTk0NBQQHFxcXhLuWUi4uLIycn5A4PoIsC3czGA08AlzrnSkJ9XVvDFo84fWAfVueX4Zxr90xeRKKL3+8nLy8v3GX0WCfd5WJmg4EXgJudc1uO87XtbrtodD8KSmvYtL/yJCsUEYkOnZ6hm9kzwCwgw8wKgO8BfgDn3G+A7wLpwCPBgG50zk0NZecdDTOflpcGwIcF5Ywe0CeUtxMRiWqdBrpz7vpOtt8B3HEiO++oy2VIWgJJsT7WFZZzDYNO5O1FRKJKj5vLpWWbxxgzsA/r9pZ3Y0UiIr1XWAO9s2udE3JSWFdYQW1DU/cUJCLSi/WoJxYd68xhGdQ3NrNqj4Yvioh0psd2uQCcnh24GLppf0V3lCMi0quFOdA73p6ZFEtaYgwfqh9dRKRTPfoM3cw4Z0QGizYV0djU3E1ViYj0Tj060AEuHduf0uoGlu8q7bStiEg06/GBPmNoOgBrC3RhVESkI+EN9BD23jchhv594lhfqAujIiId6fFn6ABnDk9n0eYijUcXEelArwj0KyZmU1nbyDtbD57iikREeq8e3+UCMD0vDY+haQBERDrQK87Q4/xeclIT2FZcdYorEhHpvXpFoAOMy0lh2Y5DNDVH9qOnREROVHjncjmOQJ8zdgAHq+pYtjPkByKJiESV8M62eBx7P39UJn6v8a8tkf8sQRGRE9FrulwSYnyMGZjCqt26wUhEpC29pssFYPLgvqzdW0aD5nUREfmYHv2Ai2NNGZJKbUOzhi+KiLSh13S5QOCBF2bwrm4wEhH5mB79xKJjpSXGMHZgiu4YFRFpQ6eBbmZPmlmRma1rZ7uZ2S/NbJuZrTWzySHv/Di7XADOGZHBB3tKqaxtOP4Xi4hEsFDO0J8CZnew/VJgRPBnHvBoqDu34+1EB84ZkUljs+O97RqPLiLSWqeB7pxbDBzqoMkVwB9cwFKgr5kN6KoCjzV5SF8SYrzqdhEROUZX9KFnA/mtlguC6z7GzOaZ2QozW3GiO4v1eZkxNJ13tuoGIxGR1rr1oqhz7jHn3FTn3NQT6D5vcc6IDHaVVLOnpLrLahMR6e26ItD3AoNaLecE13XoRPrPjzhnRCYA72zTWbqIyBFdEegvAZ8NjnaZAZQ75/Z1wfu2a1hmIgNT4nhni/rRRUSO8HXWwMyeAWYBGWZWAHwP8AM4534DvAbMAbYB1cBtoew4Mzn2xCoO1MQ5IzJ5bd0+Gpua8XnDOpxeRKRH6DTQnXPXd7LdAXce746zTiLQAc49LZO/rMhnTUEZU4akndR7iYhEgl57anv28AxivB5eXnNKe3dERHqNXhvoKQl+Zo3M5J8bDhD4I0FEJLr12kAHmDUyi71lNWzXs0ZFRHp3oJ97WgYAb2/W8EURkV4d6DmpCQzPStJj6URE6OWBDnDeaZks23mImvqmcJciIhJWERHo9Y3NLN2p2RdFJLr1+kA/Iy+NOL+Hf6kfXUSiXK8P9Dh/YPbFtzYVafiiiES1Xh/oAHPGDmDPoWrWFOjh0SISvSIi0C8Z258Yr4cXV3c6yaOISMSKiEBPifdz/qhMXl6zj6ZmdbuISHSKiEAHuHJiNger6vSsURGJWhET6OePyiI51sff1O0iIlEqYgI9zu/lkrH9+ce6/dQ26CYjEYk+ERPoEOh2qaprZNGmonCXIiLS7SIq0GcOSycjKZYXVxeGuxQRkW4XUYHu9RiXTxjAW5uKKK9pCHc5IiLdKqICHQLdLvVNzSxctz/cpYiIdKuIC/TxOSnkpifw4hqNdhGR6BJxgW5mzJ2YzZLtJRRV1Ia7HBGRbhNSoJvZbDPbbGbbzGx+G9sHm9kiM1tlZmvNbE7Xlxq6KycOxDl4aY0ujopI9Og00M3MCzwMXAqMAa43szHHNPsO8JxzbhJwHfBIVxd6PIZmJjFxUF+eW5GvGRhFJGqEcoZ+BrDNObfDOVcPPAtccUwbB/QJ/p4ChP3U+Jqpg9hyoIq1moFRRKJEKIGeDeS3Wi4IrmvtXuAmMysAXgO+1NYbmdk8M1thZiuKi0/tAykumzCAOL+HZ5fvOaX7ERHpKbrqouj1wFPOuRxgDvBHM/vYezvnHnPOTXXOTc3MzOyiXbetT5yfy8cP5MXVhVTWaky6iES+UAJ9LzCo1XJOcF1rtwPPATjn3gPigIyuKPBk3DRjCNX1TfxleX7njUVEerlQAn05MMLM8swshsBFz5eOabMHuBDAzEYTCPSwP+RzwqC+zBiaxhPv7KS+sTnc5YiInFKdBrpzrhG4C1gIbCQwmmW9md1vZnODzb4KfM7M1gDPALe6HjK85PPnDWN/Ra2GMIpIxPOF0sg59xqBi52t13231e8bgLO6trSucd5pmYzISuL3/97JZyZnY2bhLklE5JSIuDtFj2Vm3HpWLusLK1iipxmJSASL+EAH+PSkHAalxfN/FqzVwy9EJGJFRaDHx3j5wZXj2FtWw8vqSxeRCBUVgQ5w9vAMxmb34Uf/2Ex5tcali0jkiZpA93iMBz89ntLqev777xvDXY6ISJeLmkAHGJudwu1n5/Hs8nyW7tAFUhGJLFEV6AD3XHQag9Li+cbza/WYOhGJKFEX6PExXn52zUQKy2q46+kPaGzSHaQiEhmiLtABpuWm8YMrx/HO1oN876X1mjNdRCJCSHeKRqJrpg1i+8EqfvuvHWSnxvPFWcPDXZKIyEmJ2kAH+MYloygsq+XHCzczZkAfZo3MCndJIiInLCq7XI7weIwffWYcI/slc9fTq9hyoDLcJYmInLCoDnSAhBgfv79tGnF+L7c8+T67Sw6HuyQRkRMS9YEOMCAlnt/fOo3DdY185S+rNfJFRHolBXrQuJwUfvjpcazaU8YDr26kur4x3CWJiBwXBXorl40fyA3TB/PUkl18+pEl5B+qDndJIiIhU6Af4wdXjuVX109iV8lhLvzpv/j1W1vDXZKISEiiethiW8yMyycMZFpuGt9/ZQM/eX0LKfF+bp6ZG+7SREQ6pEBvR/+UOB66biIVtQ383xfXkxTn41OTcsJdlohIu9Tl0gG/18MTt0xl6pBU7vnLGr7ztw/1xCMR6bEU6J2I9Xl5+nMz+MSYfvxp6R4u/9W7vLO1ONxliYh8TEiBbmazzWyzmW0zs/nttLnGzDaY2Xoze7prywyvGJ+HX14/iW/PGc3eshpu/t37/PLNrZrUS0R6FOsslMzMC2wBLgYKgOXA9c65Da3ajACeAy5wzpWaWZZzrqij9506dapbsWLFydbf7arqGpn//FpeWbuPabmp3HXBCM4dkYGZhbs0EYkCZrbSOTe1rW2hnKGfAWxzzu1wztUDzwJXHNPmc8DDzrlSgM7CvDdLivXx82sn8rVPnMa2oipuefJ9bvn9cl74oICa+ibdZSoiYRPKGfpVwGzn3B3B5ZuB6c65u1q1+RuBs/izAC9wr3PuH2281zxgHsDgwYOn7N69u6s+R1jUNTbx+OId/OT1LQAkxnipbmhi6pBUZo3M4gvnDcPj0Zm7iHSdjs7Qu2rYog8YAcwCcoDFZjbOOVfWupFz7jHgMQh0uXTRvsMm1uflrgtGcNOMIbz64T7+ueEABqzYVcryXaW89uE+5l86irOHq0tGRE69UAJ9LzCo1XJOcF1rBcAy51wDsNPMthAI+OVdUmUP1zchhhunD+HG6UMAcM7xu3d38vCibdz8u/eZMKgvD98wiZzUhDBXKiKRLJQuFx+B7pQLCQT5cuAG59z6Vm1mE7hQeouZZQCrgInOuZL23re3XhQ9HqWH63lm+R4efXs7lbWNTBjUl8vHD2DWyCyGZyWFuzwR6YVO6qKoc64RuAtYCGwEnnPOrTez+81sbrDZQqDEzDYAi4CvdxTm0SI1MYYvzhrOE5+dytjsPqzJD8zkOPuhxbzwQUG4yxORCNPpGfqpEg1n6MdyzvHejhJueHwZAPdfcTqf1RwxInIcOjpDV6CHweG6Rr70zCre2lTEOSMyKCyrYeqQNLL6xHL5hIGc1i853CWKSA+lQO+B6hqb+NYL61i+6xBFlbU0N0N9cAz7haOy+PHVE0hLjAlzlSLS0yjQezjnHGZGUUUtP164mRdW7aV/nzh+es0EZgxND3d5ItKDKNB7mbUFZfzHU8sprW7gwlFZDM1M4tOTs9UVIyIK9N5o0/4Kbnh8GeU1DTQ1B/4/umh0FvdfMZaBfePDXJ2IhIsCvZc68v/NgYo6/rh0F0++u4tYv4dHb5zC5CF9ifV5w1yhiHS3k52cS8LEzDAz+qfE8fVLRvGnO86grqGZ6x9fylkPvsXGfRXhLlFEehAFei8yZUgaf/38TO69fAweM254fCm/e3dnuMsSkR5CzxTtZcZmpzA2O4UpQ9K47+X1fP+VDWQlB8avi0h00xl6LzUuJ4Vn5s1gzIA+fOmZVdzzl9VU1zeGuywRCSMFei/m93p4+nPTOSMvjf9dtZcvPb2KukY9xFokWinQe7m+CTE8+7kZfPeyMby5qYix31tITb1CXSQaKdAjgMdj/MfZeVwwKouGJsdlv3qH/EPV4S5LRLqZAj2CPHnrNJ68dSrFlXVc99hSCstqwl2SiHQjBXqEuWBUP57+3Awqahq48YllFFXUhrskEekmCvQINDY7hd/fNo395bWc8cM3eeCVDeEuSUS6gW79j2Ard5dy8++WUR28SNonzsfXZ49iUGo8s0Zmhbk6ETkRmsslitU1NvHjf2zmna0H2XygsmX9T66ewFVTcmhsasbn1R9qIr2FAl0A2F1ymL+tKuSZ9/ewv1Xf+vxLR/H584aFsTIRCZUCXY6yeX8lDy/axktrClvW9YnzkZeZxFWTs7lyUjbJcf4wVigi7VGgS7vKqxv4/qsbaGxqZuWeUvIP1eDzGPMvHcVnZ+YS41N3jEhPctKBbmazgV8AXuAJ59yD7bT7DLAAmOac6zCtFeg9T3Oz461NRfzk9c1s2l+J32uckZfGlMGpbDlQxQWjsrhyUrZCXiSMTirQzcwLbAEuBgqA5cD1zrkNx7RLBl4FYoC7FOi9l3OOf20p5q8rC3h17b6jtiXH+rjzguFcPSWH9KTYMFUoEr1ONtBnAvc65y4JLn8TwDn338e0ewj4J/B14GsK9MhQerietzYVMXFwX174oIC3NxezvrCC1AQ/T946jUmDU3l9/X6aneOS0/tjZuEuWSSidRToocyHng3kt1ouAKYfs4PJwCDn3Ktm9vUOCpkHzAMYPHhwCLuWcEtNjOEzU3IA+Polo/jqxSNZtvMQX31uNZ9+dAnnnZbJ25uLAbhx+mB+8Klx4SxXJKqddGeomXmAnwFf7aytc+4x59xU59zUzMzMk921hIHHY8wcls6Ld53NoNSEljD/5LgB/HnZHr6xYC21DZrtUSQcQjlD3wsMarWcE1x3RDIwFng7+Od2f+AlM5vbWbeL9F6ZybEs/Mq5bNhXQbzfy/CsJLJT43ls8Q5Kq+v57c1T1P0i0s1COUNfDowwszwziwGuA146stE5V+6cy3DO5TrncoGlgMI8CsTHeJkyJJUxA/sQ4/PwrTmj+fac0by+4QCXPLSY1z7cR3NzeIbFikSjTgPdOdcI3AUsBDYCzznn1pvZ/WY291QXKL3L7Wfn8elJ2Ww5UMUX//wBcx9+96gbmETk1NGNRXJK1DY08bN/buGxxTsA+NSkbL5/5ViSYvVccpGT0dEoF90hIqdEnN/Lt+aMZvsP53DPRafx4uq9zPvDCsJ1AiESDRTockp5PcaXLxrBfXNPZ8n2Eq58+N+s2lMa7rJEIpL+/pVuccP0IRSU1vDXlQV8+tEl5GUk8uULRzB7bH9ifd5wlycSEdSHLt3qQEUtf3xvN79etK1l3VVTcrh22iCm5aaFsTKR3kGzLUqPs7+8lv/84wrWFJS3rEtLjGHG0DRmjcxizrgBbN5fSUNTMzOGpoexUpGeRYEuPdq6veXc/8oGSqrq2F58GIA4v4fahmYA0hNjmDksnXvnnk56YoxuWJKopkCXXqOgtJrtxYd5cfVeYrweyqobeHfbQarqGgFITfDz02smMGVwGn3ifQp3iToKdOn13t5cxAOvbmRbUVXLukmD+/LojVPonxIXxspEupcCXSJGdX0j3/7fdazJL6OwvIZhmUn86fbppCbGhLs0kW6hQJeItGhzEXf8zwqSYn387xfPZGhmUrhLEjnldKeoRKTzR2bx8l1n4zG48+lVH5u2t76xmZW7S7nz6Q/46nNrWLh+P/WNzWGqVuTU0xm69HqLNhVx21PLmTk0nRifh0OH6/nG7FHc8Yfl1DY0kxzro7HZUdPQxMyh6QzPSuKy8QOYruGQ0gupy0Ui3kNvbOFXb20j3u9tGREDMPv0/nz/yrEkxHj56etbWLAyn8q6RmJ9Hh69cQrnj8oKY9Uix0+BLlGhudnh8RgbCiu4/5X1XDZ+IDfNGPKxdvvLa7nlyffZUlTJnLEDcDgeuHIcaYkxVNc3sutgNWMG9gnDJxDpnAJd5BjV9Y186elVvLmpqGXd9WcMZtmOEnYcPEyc38OQtESGZSVy65l5nJGnaQmkZ1Cgi7SjvrGZtQVlPP7ODhauPwBAQoyXT4zpR2l1Axv2VVBe3cCPrx7PFROzw1ytiAJdpFPOObYXH6ZPvI+s5I9uVCo9XM9lv3qXvWU15GUkYkCMz8PnzxvGlZOy2V1ymL2lNazdW86lY/uTlhiDA5JjfVTWNfKz17ewvbiK8poGdhQfpm+Cn9z0ROZOHMjVU3J0p6scNwW6yEmorG3g839ayaZ9lZQcrm9ZnxLvp7ymoWW5b4KfsurA8mn9kiirbqCoso54v5f+KXH0ifMdNRkZBOasuWJCNtOHplHb0MyEQSnUNzYzcVBfhb20SYEu0kUamprZvL+Sp5bsYn1hBReP6Uesz8PIfsn88O8b2VF8mNQEP0PSE+kT7+fWM4dw/sislnDeVlTJgJR4nnhnJz9/Y0u7+zkjN43/+sRpTM9Lo9kFHhQCUFRRy1+W51Na3cA9F48gOc7fLZ9beg4Fukg3aGhqJv9Qdch3rBZX1pEQ46WitoFDh+tpaHIs3VHCil2lrC8sZ195LQD9+8TxuXOHUl3XyNPv72lZPygtnkdumMK4nJTjrrWp2eGcw+cN/d5C55z+augBFOgivUxZdT0/fG0jz60oOGoqYYBbz8zlwtFZzH/+Q/aW1XDmsHScg6LKWvxeD+NzUnAOVu4upbq+ia9dMpKrpuQAUF7TwB+W7OLXi7aREONlbHYKK3eXEu/3MiwrifmXjmLz/krSE2MY0S+Z+15eT2l1A83Nji0HKhmelcStZ+aSnRpPvz5xvLWxiD8t2825IzK5b+7peDwK/FPtpAPdzGYDvwC8wBPOuQeP2f5fwB1AI1AM/IdzbndH76lAF+lcbUMTzsG72w6yJr+Ms0dktDzwY29ZDb94YwuLNhfTr08s1XVNHK5v5EBFHQAZSbEMSInjw73lpMT78XqMqtpG6psC/zhk943H5zVGZCWzOr+Mg1V1R+3bY9DcKh6GZyVRVl3Pwap62nLj9MF87RMjNVHaKXZSgW5mXmALcDFQACwHrnfObWjV5nxgmXOu2sy+AMxyzl3b0fsq0EW6nnOOksP1LQ8CqWts4k9L97B+bzkvrNpLQoyXJ26ZyoScviTGHv1I4aq6Rp54Zwd7SqoZ3i+JqtpGPjszl4RYLwtWFHD11BzqGpt5fmUB+8pr6ZvgZ+6EgeRlJHLfyxt4askuMpJi+MbsUXxmcg7NzlHf1Eycz6sz9y7Q1Oy4+5lVPHLTlJMK9JnAvc65S4LL3wRwzv13O+0nAb92zp3V0fsq0EW6V0FpNT6P55TNH7+2oIzvvrie1fllxPo8NDU7GpsdsT4Pt56ZS3V9E/953lByUhNCej/nHNX1TR/7h+dkbNpfwZ+W7mb5zlKumpLDHefkHXVd4OU1hZRW13Pj9CEtF6LDbemOEv61pZhH397OI/6H+OQDb7Qb6KEcqWwgv9VyATC9g/a3A38PvVwR6Q6hBumJGp/Tl+e/cCYvfFDArxdtY3hmEv1T4vjL8nx+u3gHAH9cups4v4f6xmbSk2K5YGQW/3neUMbzEiAAAAiPSURBVNKTYimpqiM3PZEn3t3Br97cRn1TM3WNzcw+vT/zzhvK5MGpx11TZW0Dq/aU8e/tB6mpb+LZ9/Nbupx+8NpGnluRT/+UOA5U1HK4rom9ZTUAvL7+ABeMyuLiMf1YU1DGil2l3DB9MKf1S2bnwcPE+jwUlNYweXBfvB476YvFhw7Xk5rg52BVPesKy/nWCx9yoCJwTaSu1QyhiXnTgTfafZ9QztCvAmY75+4ILt8MTHfO3dVG25uAu4DznHN1bWyfB8wDGDx48JTduzvsZheRCJF/qJqX1hTy+vr9rCkoJyMphoykWDbtrzyqnd9rNDQFMikzOZaJg/ryzw0H8HsDgZkU6+OcEZlMzU1l6pC0ljl3dpccZuO+Ci4e0x+vx1hfWM7/+8dmVueXHXWvwDkjMvjuZWPYfKCSPYeqeerfu0iM9RHr8zCwbzzT89KI9Xn46etbqGw1yVtHJuSk8MnxA5iQ05d95bWMzU5heFboc/O/unYfdz3zARlJsRRXfhSb03JTaWhyDM1I5BuXjiIrORYzO+k+9JC6XMzsIuBXBMK86GNvdAx1uYhEp8amZhqaHPExXjYUVvD4OztobHZkJMXw+3/vIi0xhtfuPqela6i8uoE7n/6Ad7cdbPP9zhyWzns7SnAOYrwepgxJ5b0dJQBMGZLKJ8b048pJ2cT5vCE/h7a8poFX1+5jbUEZ/frEMap/Mve/soGkWB8zh6XjMcPnMfaV17Jk+0FKqxuOev1l4wdw39zTKSyrZfmuQ5gFhp8Oz0piRL9kAA5W1fHvbQf5+l/XUt/UTGqCn9SEGC4Z25/PnTOUtHYuLp9soPsIXBS9ENhL4KLoDc659a3aTAIWEDiT39rp0UKBLiIft3hLMbnpiQxOP7p7qLnZsXhrMTOHpZN/qIbtxVXc//IG9pbVkBTrY8bQdDKSYnhpTSHDMpNoaGrmxhlDuLmN2TZPVEOwq8Z/zNj9xqZm1hVWsLe0hv0VtWzcV8HzHxTQXrSeNTydr1x0Gr9+axv/2lIMwF8/P5NpuaFNANcVwxbnAA8RGLb4pHPuB2Z2P7DCOfeSmb0BjAP2BV+yxzk3t6P3VKCLyMkqqqglM9gVAR9NoRxuK3eX8p2/rSMhxsvZwzMYmplIbUMTG/dV8of3drUMB501MpNbz8xl1sjQ5+XXjUUiIj3EroOH+dE/NlFW3cDvb5tGnN97XK/vKNC7bjyQiIh0KjcjkUdvmnJK3lsPiRYRiRAKdBGRCKFAFxGJEAp0EZEIoUAXEYkQCnQRkQihQBcRiRAKdBGRCKFAFxGJEAp0EZEIoUAXEYkQCnQRkQihQBcRiRAKdBGRCKFAFxGJEAp0EZEIoUAXEYkQCnQRkQihQBcRiRAKdBGRCKFAFxGJECEFupnNNrPNZrbNzOa3sT3WzP4S3L7MzHK7ulAREelYp4FuZl7gYeBSYAxwvZmNOabZ7UCpc2448HPgR11dqIiIdCyUM/QzgG3OuR3OuXrgWeCKY9pcAfxP8PcFwIVmZl1XpoiIdMYXQptsIL/VcgEwvb02zrlGMysH0oGDrRuZ2TxgXnCxzszWnUjRUSCDY46dtNCxaZ+OTcci5fgMaW9DKIHeZZxzjwGPAZjZCufc1O7cf2+hY9M+HZv26dh0LBqOTyhdLnuBQa2Wc4Lr2mxjZj4gBSjpigJFRCQ0oQT6cmCEmeWZWQxwHfDSMW1eAm4J/n4V8JZzznVdmSIi0plOu1yCfeJ3AQsBL/Ckc269md0PrHDOvQT8DvijmW0DDhEI/c48dhJ1Rzodm/bp2LRPx6ZjEX98TCfSIiKRQXeKiohECAW6iEiECEugdzaVQKQzs0FmtsjMNpjZejP7cnB9mpn908y2Bv83NbjezOyXweO11swmh/cTnFpm5jWzVWb2SnA5LzilxLbgFBMxwfVRN+WEmfU1swVmtsnMNprZTH1vAszsnuB/T+vM7Bkzi4u27063B3qIUwlEukbgq865McAM4M7gMZgPvOmcGwG8GVyGwLEaEfyZBzza/SV3qy8DG1st/wj4eXBqiVICU01AdE458QvgH865UcAEAscp6r83ZpYN3A1Mdc6NJTCA4zqi7bvjnOvWH2AmsLDV8jeBb3Z3HT3pB3gRuBjYDAwIrhsAbA7+/lvg+lbtW9pF2g+B+xzeBC4AXgGMwN19vmO/PwRGXs0M/u4LtrNwf4ZTeGxSgJ3HfkZ9bxx8dLd6WvC78ApwSbR9d8LR5dLWVALZYaijRwj+qTcJWAb0c87tC27aD/QL/h5Nx+wh4P8AzcHldKDMOdcYXG792Y+acgI4MuVEpMoDioHfB7uknjCzRPS9wTm3F/gJsAfYR+C7sJIo++7oomgYmVkS8DzwFedcRettLnDqEFVjSs3sMqDIObcy3LX0UD5gMvCoc24ScJiPuleA6PzeAASvG1xB4B+9gUAiMDusRYVBOAI9lKkEIp6Z+QmE+Z+dcy8EVx8wswHB7QOAouD6aDlmZwFzzWwXgVk9LyDQZ9w3OKUEHP3Zo23KiQKgwDm3LLi8gEDAR/v3BuAiYKdzrtg51wC8QOD7FFXfnXAEeihTCUS04NTCvwM2Oud+1mpT6ykUbiHQt35k/WeDoxZmAOWt/sSOGM65bzrncpxzuQS+F285524EFhGYUgI+flyiZsoJ59x+IN/MRgZXXQhsIMq/N0F7gBlmlhD87+vIsYmu706YLmDMAbYA24Fvh/tCQhg+/9kE/ixeC6wO/swh0If3JrAVeANIC7Y3AiODtgMfEriSH/bPcYqP0SzgleDvQ4H3gW3AX4HY4Pq44PK24Pah4a67G47LRGBF8LvzNyBV35uWY3MfsAlYB/wRiI22745u/RcRiRC6KCoiEiEU6CIiEUKBLiISIRToIiIRQoEuIhIhFOgiIhFCgS4iEiH+P8ZEYu4ZmPJ9AAAAAElFTkSuQmCC
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># validation on the dev dataset</span>
<span class="n">learner</span><span class="o">.</span><span class="n">validate</span><span class="p">(</span><span class="n">databunch</span><span class="o">.</span><span class="n">valid_dl</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[0.23397401, tensor(0.9245), array(0.758545, dtype=float32)]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># validation on the test dataset</span>
<span class="n">learner</span><span class="o">.</span><span class="n">validate</span><span class="p">(</span><span class="n">test_dl</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[0.23983945, tensor(0.9225), array(0.749302, dtype=float32)]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Conclusion">Conclusion<a class="anchor-link" href="#Conclusion">&#182;</a></h2><p>We reached scores ranking in the top 3% for the challenge, by just using simple Bert and one cycle learning. With the customization work it is now possible to try out multiple new techniques of fast.ai to get even better scores.</p>
<p>Just to name a few: Discriminative Fine-tuning, Gradual unfreezing, LabelSmoothing, MixUp,Â â€¦</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">nbdev.export</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">notebook2script</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Converted 00_fastbert.ipynb.
Converted 01_task3.ipynb.
Converted index.ipynb.
</pre>
</div>
</div>

</div>
</div>

</div>
</div>
 

